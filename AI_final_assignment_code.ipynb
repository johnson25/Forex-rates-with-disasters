{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T00:05:05.276626Z",
     "start_time": "2020-05-22T00:05:05.262541Z"
    }
   },
   "source": [
    "# Importing packages and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:08:54.504201Z",
     "start_time": "2020-06-16T01:08:54.488907Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{max-width:100%!important;width:auto!important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:08:54.691127Z",
     "start_time": "2020-06-16T01:08:54.507193Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:08:59.835775Z",
     "start_time": "2020-06-16T01:08:54.694173Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas_bokeh\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.layouts import row\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import neighbors\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Currency exchange rates dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:00.084029Z",
     "start_time": "2020-06-16T01:08:59.839330Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/johns/desktop/AI/dataset with factors.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing factors influencing FOREX rates dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:00.329585Z",
     "start_time": "2020-06-16T01:09:00.087029Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"C:/Users/johns/desktop/AI/FOREX factors.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing US natural disaster dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:00.544607Z",
     "start_time": "2020-06-16T01:09:00.331181Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"C:/Users/johns/downloads/events-US-1980-2020.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Currency exchange rates dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:00.762586Z",
     "start_time": "2020-06-16T01:09:00.547835Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.shape, df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:00.989751Z",
     "start_time": "2020-06-16T01:09:00.767573Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['Date'] = pd.to_datetime(df1['Date'], format = \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:01.196825Z",
     "start_time": "2020-06-16T01:09:00.993114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting date column from object data type to date data type\n",
    "# Creating a new column to know the day of the provided date\n",
    "# Removing the weekend data as it is mostly null \n",
    "\n",
    "df1['day_of_week'] = df1['Date'].dt.day_name()\n",
    "df1 = df1[~df1['day_of_week'].isin(['Saturday', 'Sunday'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:01.399628Z",
     "start_time": "2020-06-16T01:09:01.198820Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:01.941616Z",
     "start_time": "2020-06-16T01:09:01.401824Z"
    }
   },
   "outputs": [],
   "source": [
    "df1=df1.interpolate(method ='linear', limit_direction ='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:02.161854Z",
     "start_time": "2020-06-16T01:09:01.943588Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:02.369033Z",
     "start_time": "2020-06-16T01:09:02.164333Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning FOREX factors dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:02.589103Z",
     "start_time": "2020-06-16T01:09:02.371994Z"
    }
   },
   "outputs": [],
   "source": [
    "df2['Date'] = pd.to_datetime(df2['Date'], format = \"%d/%m/%Y\")\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging currency exchange rates dataset and FOREX factors datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:02.825762Z",
     "start_time": "2020-06-16T01:09:02.591605Z"
    }
   },
   "outputs": [],
   "source": [
    "forex_df = pd.merge(df1,df2, how = 'outer', on = \"Date\")\n",
    "forex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:03.045618Z",
     "start_time": "2020-06-16T01:09:02.827756Z"
    }
   },
   "outputs": [],
   "source": [
    "forex_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:03.414737Z",
     "start_time": "2020-06-16T01:09:03.048355Z"
    }
   },
   "outputs": [],
   "source": [
    "forex_df.to_csv(r'C:/users/johns/desktop/AI/actual_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T15:39:07.279595Z",
     "start_time": "2020-05-27T15:39:07.276611Z"
    }
   },
   "source": [
    "### Cleaning US natural disaster dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:03.625809Z",
     "start_time": "2020-06-16T01:09:03.416727Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.drop(['End Date'], axis=1)\n",
    "df3['Begin Date'] = pd.to_datetime(df3['Begin Date'],format='%Y-%m-%d').dt.date.astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging US Natural disater dataset with FOREX dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:03.867997Z",
     "start_time": "2020-06-16T01:09:03.627756Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df3.rename({'Begin Date' : 'Date'}, axis = 1)\n",
    "\n",
    "disaster_df = pd.merge(forex_df,df3 , how = 'left', on = \"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the final FOREX dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:04.156314Z",
     "start_time": "2020-06-16T01:09:03.870168Z"
    }
   },
   "outputs": [],
   "source": [
    "disaster_df['disaster_event'] = disaster_df['Disaster']\n",
    "disaster_df['disaster_event'].loc[~disaster_df['disaster_event'].isnull()] = 1  # not nan\n",
    "disaster_df['disaster_event'].loc[disaster_df['disaster_event'].isnull()] = 0  # nan\n",
    "disaster_df['Damage Cost (Millions of Dollars)'].loc[disaster_df['Damage Cost (Millions of Dollars)'].isnull()] = 0  # nan\n",
    "disaster_df['Deaths'].loc[disaster_df['Deaths'].isnull()] = 0  # nan\n",
    "disaster_df['Disaster'].fillna(\"No disaster\", inplace = True)\n",
    "disaster_df['Name'].fillna(\"No disaster\", inplace = True)\n",
    "\n",
    "disaster_df = disaster_df[['Date','Name','disaster_event', 'Disaster', 'Damage Cost (Millions of Dollars)', 'Deaths', 'Goldprices', 'Debt', 'GDP', 'CPI', 'PPI','EUR:Euro', 'GBP:Pound Sterling', 'AUD:Australian Dollar', 'CAD:Canadian Dollar', 'CHF:Swiss Franc'\n",
    "               , 'JPY:Japanese Yen', 'NZD:New Zealand Dollar']]\n",
    "\n",
    "disaster_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis on Time - Series data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:04.760665Z",
     "start_time": "2020-06-16T01:09:04.158226Z"
    }
   },
   "outputs": [],
   "source": [
    "disaster_df.plot_bokeh.line(x = 'Date', y = ['EUR:Euro', 'GBP:Pound Sterling', 'AUD:Australian Dollar',\n",
    "       'CAD:Canadian Dollar', 'CHF:Swiss Franc', 'NZD:New Zealand Dollar'], ylabel = 'Value of currency for 1 USD', title = 'Comparision of currencies against USD', figsize = (1500,800), panning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:05.037714Z",
     "start_time": "2020-06-16T01:09:04.762660Z"
    }
   },
   "outputs": [],
   "source": [
    "disaster_df.plot_bokeh(kind='scatter',x = 'GDP', y = 'Debt', ylabel = 'Debt' , title = 'GDP vs Debt', figsize = (1500,800), panning = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:05.332079Z",
     "start_time": "2020-06-16T01:09:05.041693Z"
    }
   },
   "outputs": [],
   "source": [
    "disaster_df[disaster_df['disaster_event']==1].count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:05.605847Z",
     "start_time": "2020-06-16T01:09:05.334040Z"
    }
   },
   "outputs": [],
   "source": [
    "disaster_count1 = disaster_df[disaster_df.disaster_event==1]\n",
    "disaster_count2 = pd.DataFrame(disaster_count1['Disaster'].value_counts())\n",
    "#factor_cmap('fruits', palette=Spectral6, factors=fruits)\n",
    "disaster_count2.plot_bokeh(kind='bar', y = 'Disaster', xlabel = 'Disaster type', ylabel = 'Number of occurences', title = 'Number of instances of each disaster type in the past 19 years', figsize = (1500,600), legend = 'top_right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:05.868466Z",
     "start_time": "2020-06-16T01:09:05.607951Z"
    }
   },
   "outputs": [],
   "source": [
    "featured_data = disaster_df.copy()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "featured_data['Disaster'] = lbl.fit_transform(featured_data['Disaster'])\n",
    "featured_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:07.610835Z",
     "start_time": "2020-06-16T01:09:05.870028Z"
    }
   },
   "outputs": [],
   "source": [
    "corrmat = disaster_df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(disaster_df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:07.861917Z",
     "start_time": "2020-06-16T01:09:07.612078Z"
    }
   },
   "outputs": [],
   "source": [
    "featured_data['year'] = featured_data['Date'].dt.year\n",
    "featured_data['month'] = featured_data['Date'].dt.month\n",
    "featured_data['day'] = featured_data['Date'].dt.day\n",
    "featured_data['week'] = featured_data['Date'].dt.week\n",
    "\n",
    "featured_data.drop(['Date', 'Name'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:09:08.087754Z",
     "start_time": "2020-06-16T01:09:07.864131Z"
    }
   },
   "outputs": [],
   "source": [
    "featured_data = featured_data[['year','month','day','week','disaster_event', 'Disaster', 'Damage Cost (Millions of Dollars)', 'Deaths', 'Goldprices', 'Debt', 'GDP', 'CPI', 'PPI','EUR:Euro', 'GBP:Pound Sterling', 'AUD:Australian Dollar', 'CAD:Canadian Dollar', 'CHF:Swiss Franc'\n",
    "               , 'JPY:Japanese Yen', 'NZD:New Zealand Dollar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:10:01.040810Z",
     "start_time": "2020-06-16T01:10:00.780031Z"
    }
   },
   "outputs": [],
   "source": [
    "features_lagged = featured_data.copy()\n",
    "for items in features_lagged.columns:\n",
    "    features_lagged[items+'_Lags']= features_lagged[items].shift(2)\n",
    "\n",
    "features_lagged = features_lagged.dropna()\n",
    "features_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T23:11:50.284863Z",
     "start_time": "2020-06-15T23:11:50.081477Z"
    }
   },
   "source": [
    "## Linear Regression Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:02:25.516848Z",
     "start_time": "2020-06-16T01:02:25.234078Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_model(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values\n",
    "        y = dataset[col].values\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        regressor = LinearRegression()  \n",
    "        regressor.fit(x_train, y_train)\n",
    "        y_pred = regressor.predict(x_test)\n",
    "        pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:02:32.566877Z",
     "start_time": "2020-06-16T01:02:26.472359Z"
    }
   },
   "outputs": [],
   "source": [
    "linear_model(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees with Regression Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:01:02.134048Z",
     "start_time": "2020-06-16T01:01:01.912313Z"
    }
   },
   "outputs": [],
   "source": [
    "def decisiontree_regressor(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values\n",
    "        y = dataset[col].values\n",
    "        \n",
    "        sc_x = MinMaxScaler()\n",
    "        x = sc_x.fit_transform(x)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        DT_regressor = DecisionTreeRegressor(criterion='mse', max_depth=10) \n",
    "                             \n",
    "        DT_regressor.fit(x_train, y_train)\n",
    "        y_pred = DT_regressor.predict(x_test)\n",
    "        pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        plt.legend()\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:01:12.748909Z",
     "start_time": "2020-06-16T01:01:02.137027Z"
    }
   },
   "outputs": [],
   "source": [
    "decisiontree_regressor(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:03:41.390099Z",
     "start_time": "2020-06-16T01:03:41.158777Z"
    }
   },
   "outputs": [],
   "source": [
    "def knn_algorithm(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values\n",
    "        y = dataset[col].values\n",
    "        \n",
    "        sc_x = MinMaxScaler()\n",
    "        x = sc_x.fit_transform(x)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        knn_model = neighbors.KNeighborsRegressor(n_neighbors = 4)\n",
    "        knn_model.fit(x_train, y_train)\n",
    "        y_pred = knn_model.predict(x_test)\n",
    "        \n",
    "        pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:03:48.291804Z",
     "start_time": "2020-06-16T01:03:41.392180Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_algorithm(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:03:48.542239Z",
     "start_time": "2020-06-16T01:03:48.294792Z"
    }
   },
   "outputs": [],
   "source": [
    "def xgb_model(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values\n",
    "        y = dataset[col].values\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scale_x = scaler.fit_transform(x)\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(scale_x, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        model = XGBRegressor(objective ='reg:squarederror',\n",
    "                     seed=100,\n",
    "                     n_estimators=100,\n",
    "                     max_depth=3,\n",
    "                     learning_rate=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=1,\n",
    "                     colsample_bytree=1,\n",
    "                     colsample_bylevel=1,\n",
    "                     gamma=0)\n",
    "\n",
    "        # Train the regressor\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:03:56.298978Z",
     "start_time": "2020-06-16T01:03:48.546641Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:03:56.527318Z",
     "start_time": "2020-06-16T01:03:56.302225Z"
    }
   },
   "outputs": [],
   "source": [
    "def svr_algorithm(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values\n",
    "        y = dataset[col].values\n",
    "        \n",
    "        sc_x = MinMaxScaler()\n",
    "        x = sc_x.fit_transform(x)\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "        svr_model = SVR(kernel='poly')\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        \n",
    "        svr_model.fit(x_train, y_train)\n",
    "        y_pred = svr_model.predict(x_test)\n",
    "        \n",
    "        pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T01:04:04.237219Z",
     "start_time": "2020-06-16T01:03:56.529213Z"
    }
   },
   "outputs": [],
   "source": [
    "svr_algorithm(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T23:09:20.494397Z",
     "start_time": "2020-06-15T23:09:20.290622Z"
    }
   },
   "source": [
    "## Artificial Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T17:02:59.104393Z",
     "start_time": "2020-06-16T17:02:58.884589Z"
    }
   },
   "outputs": [],
   "source": [
    "def ann_algorithm(dataset):\n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values    \n",
    "        y = dataset[col].values\n",
    "\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        x_scale = min_max_scaler.fit_transform(x)\n",
    "        x_scale\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_scale, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        print('USD vs', col)\n",
    "        print(' \\n ')\n",
    "        \n",
    "        ann_model = Sequential()\n",
    "        ann_model.add(Dense(18, input_dim=39, activation='relu'))\n",
    "        ann_model.add(Dense(12, activation='relu'))\n",
    "        ann_model.add(Dense(1))\n",
    "        ann_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        #ann_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        #early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1)\n",
    "        ann_model.fit(x_train, y_train, epochs=1, batch_size=16, verbose = 0, validation_split=0.2, shuffle=False)\n",
    "        \n",
    "        y_pred = ann_model.predict(x_test)\n",
    "        #y_train_pred_nn = nn_model.predict(x_train)\n",
    "\n",
    " \n",
    "\n",
    "        #pred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "        pred_df = pd.DataFrame(pd.concat({'Actual': pd.DataFrame(y_test), 'Predicted': pd.DataFrame(y_pred)}, ignore_index=True, axis=1))\n",
    "\n",
    " \n",
    "\n",
    "        pred_df_head = (pred_df.head(20))\n",
    "        pred_df_head = pred_df_head.rename({0 : 'Actual', 1:'Predicted'}, axis =1)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "\n",
    " \n",
    "\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        \n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Accuracy:', accuracy)\n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T17:03:14.408436Z",
     "start_time": "2020-06-16T17:03:00.118892Z"
    }
   },
   "outputs": [],
   "source": [
    "ann_algorithm(features_lagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T17:04:06.720636Z",
     "start_time": "2020-06-16T17:04:06.507579Z"
    }
   },
   "outputs": [],
   "source": [
    "def lstm_algorithm(dataset):\n",
    "    \n",
    "    for col in dataset.columns[13:20]:\n",
    "        x = dataset[dataset.columns.difference([col, col + '_lags'])].values    \n",
    "        y = dataset[col].values\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        x_scale = min_max_scaler.fit_transform(x)\n",
    "        x_scale\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_scale, y, test_size=0.25, random_state=0)\n",
    " \n",
    "        #LSTM expects the input data in a specific 3D format of sample size, time steps, no. of input features\n",
    "    \n",
    "        x_train = x_train.reshape(x_train.shape[0],1,x_train.shape[1])\n",
    "        x_test = x_test.reshape(x_test.shape[0],1, x_test.shape[1])\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(units=72, dropout=0.2, recurrent_dropout=0.2, \n",
    "                       input_shape=(x_train.shape[1], x_train.shape[2]), \n",
    "                       return_sequences=True))\n",
    "\n",
    "        model.add(LSTM(units=72, dropout=0.2, recurrent_dropout=0.2, \n",
    "                       return_sequences=False))\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "        model.add(Dense(1, activation='relu'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam' )\n",
    "        model.summary()\n",
    "        # fit network\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1, batch_size=16, validation_data=(x_test, y_test), verbose=2, shuffle=True)\n",
    "        \n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        x_test=x_test.reshape((x_test.shape[0],x_test.shape[2])) \n",
    "        \n",
    "        pred_df = pd.DataFrame(pd.concat({'Actual': pd.DataFrame(y_test), 'Predicted': pd.DataFrame(y_pred)}, ignore_index=True, axis=1))\n",
    "        pred_df_head = pred_df.head(20)\n",
    "        pred_df_head = pred_df_head.rename({0 : 'Actual', 1:'Predicted'}, axis =1)\n",
    "        print(pred_df_head)\n",
    "        \n",
    "        \n",
    "        plt.plot(pred_df_head)\n",
    "        \n",
    "        pred_df_head.plot(kind='bar',figsize=(10,8))\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        error = abs(y_pred - y_test)\n",
    "        mape = np.mean(100 * (error / y_test))\n",
    "        accuracy = 100 - mape\n",
    "        \n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "        print('Mean Absolute Percentage Error:', mape)\n",
    "        print('Accuracy:', accuracy)\n",
    "\n",
    "        print(' \\n ')\n",
    "        print('---------------------------------------------')\n",
    "        print(' \\n ')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-16T17:04:07.684Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_algorithm(features_lagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
